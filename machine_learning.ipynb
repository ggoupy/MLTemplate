{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=10000,suppress=True)\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesure des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retourne les mesures <precision>, <recall>, <accuracy> pour une prédiction donnée\n",
    "def precision_recall_accuracy(ytrue, ypred):\n",
    "    precision = precision_score(ytrue, ypred)\n",
    "    recall = recall_score(ytrue, ypred)\n",
    "    accuracy = accuracy_score(ytrue, ypred)\n",
    "    print(f\"precision:{precision} | recall:{recall} | accuracy:{accuracy}\")\n",
    "\n",
    "# Recall = TP / (TP+FN) => Parmi les vrais à \"1\", combien ont été sélectionnés ?\n",
    "# Precision = TP / (TP+FP) => Parmi les prédits à \"1\", combien le sont réellement ?\n",
    "# Accuracy = (TP + TN) / (TP+TN+FP+FN) => Le nombre de bien prédits sur l'ensemble (\"1\" ou \"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"d\"](https://miro.medium.com/max/724/1*Z54JgbS4DUwWSknhDCvNTQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divise le dataset selon la taille spécifiée\n",
    "def split_train_test(X, y, size=0.33):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=size, random_state=1)\n",
    "    print(f\"Taille du training set après réduction : X:{X_train.shape}, y:{y_train.shape}\")\n",
    "    print(f\"Taille du test set après réduction : X:{X_test.shape}, y:{y_test.shape}\")\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nom des colonnes associées aux données d'entrée\n",
    "COLS = np.array([\"...\"])\n",
    "\n",
    "# Test les features du dataset pour choisir les meilleures\n",
    "def feature_selection(X, y_train, X_test, y_test, nom_cols=COLS):\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    importances=clf.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in clf.estimators_],axis=0)\n",
    "    sorted_idx = np.argsort(importances)[::-1]\n",
    "    features = nom_cols\n",
    "    padding = np.arange(X_train.size/len(X_train)) + 0.5 \n",
    "    plt.barh(padding, importances[sorted_idx],xerr=std[sorted_idx], align='center') \n",
    "    plt.yticks(padding, features[sorted_idx]) \n",
    "    plt.xlabel(\"Relative Importance\")\n",
    "    plt.title(\"Variable Importance\") \n",
    "    plt.show()\n",
    "    KNN=KNeighborsClassifier(n_neighbors=5)\n",
    "    scores=np.zeros(X_train.shape[1]+1)\n",
    "    for f in np.arange(0, X_train.shape[1]+1):\n",
    "        X1_f = X_train[:,sorted_idx[:f+1]]\n",
    "        X2_f = X_test[:,sorted_idx[:f+1]]\n",
    "        KNN.fit(X1_f,y_train)\n",
    "        YKNN=KNN.predict(X2_f)\n",
    "        scores[f]=np.round(accuracy_score(y_test,YKNN),3)\n",
    "    plt.plot(scores)\n",
    "    plt.xlabel(\"Nombre de Variables\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Evolution de l'accuracy en fonction des variables\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applique un algorithme GridSearch sur le modèle passé associé à ses arguments à test\n",
    "# X et y doivent être l'ensemble du dataset (split dans GridSearch avec cross validation)\n",
    "def gridsearch(X, y, model, opts):\n",
    "    gs = GridSearchCV(model, opts, cv=5, scoring=\"accuracy\")\n",
    "    gs = gs.fit(X,y)\n",
    "    print(f\"Meilleur score : {gs.best_score_}\")\n",
    "    print(f\"Meilleurs params : {gs.best_params_}\")\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation de la fiabilité des classifieurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Liste de classifieur à tester\n",
    "CLFS = {\n",
    "    'LinearSVC': LinearSVC(random_state=1),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVC': SVC(random_state=1),\n",
    "    'GaussianNB' : GaussianNB(),\n",
    "    'RF': RandomForestClassifier(random_state=1),\n",
    "    'SGDClassifier': SGDClassifier(random_state=1),\n",
    "    'LogisticRegression': LogisticRegression(random_state=1),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=1),\n",
    "    \"MultilayerPerceptron\": MLPClassifier(random_state=1),\n",
    "    \"Bagging\": BaggingClassifier(base_estimator=SVC(), random_state=1)\n",
    "}\n",
    "\n",
    "# Evaluation des classifieur spécifiés avec cross-validation\n",
    "def kfcv_test_classifiers(X, y, scaler=StandardScaler(), clfs=CLFS):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=1)        \n",
    "    for i in clfs:\n",
    "        clf = clfs[i]\n",
    "        time_begin = time.time()\n",
    "        if scaler != None:\n",
    "            clf = make_pipeline(scaler, clf)\n",
    "        cv_acc = cross_val_score(clf, X, y, scoring='accuracy', cv=kf)\n",
    "        time_end = time.time()\n",
    "        print(f\"Classifier {i} : \")\n",
    "        print(f\"\\tExecution time = {time_end-time_begin}\")\n",
    "        print(\"\\tAccuracy : {0:.3f} +/- {1:.3f}\".format(np.mean(cv_acc), np.std(cv_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des données : (1631, 22)\n",
      "Taille du training set après réduction : X:(1092, 22), y:(1092,)\n",
      "Taille du test set après réduction : X:(539, 22), y:(539,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>DL</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>Classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>186</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>115</td>\n",
       "      <td>117</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>188</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>119</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>182</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>153</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>182</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>1627</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>194</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>124</td>\n",
       "      <td>130</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>1628</td>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>181</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>1629</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>181</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>125</td>\n",
       "      <td>127</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>1630</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>195</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>1631</td>\n",
       "      <td>115</td>\n",
       "      <td>6</td>\n",
       "      <td>95</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>182</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>116</td>\n",
       "      <td>118</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1631 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID   LB  AC   FM  UC  ASTV  MSTV  ALTV  MLTV  DL  ...  Min  Max  Nmax  \\\n",
       "0        1  114   3    0   3    24   3.2     0  16.2   2  ...   52  186     8   \n",
       "1        2  115   5   52   3    22   3.6     0  19.6   1  ...   50  188     8   \n",
       "2        3  115   9   54   5    27   2.3     0  12.4   0  ...   53  182     7   \n",
       "3        4  114  10   69   8    28   2.2     0  12.2   1  ...   55  153     7   \n",
       "4        5  114   4   31   6    27   2.4     0  13.5   0  ...   54  182     6   \n",
       "...    ...  ...  ..  ...  ..   ...   ...   ...   ...  ..  ...  ...  ...   ...   \n",
       "1626  1627  132   0   64   1    29   2.9     0  15.1   7  ...   50  194    11   \n",
       "1627  1628  120   9  123   1    28   3.4     0  21.7   1  ...   55  181    13   \n",
       "1628  1629  120   6   56   1    28   3.2     0  12.4   1  ...   53  181     9   \n",
       "1629  1630  120   5   90   6    27   3.7     0  24.2   0  ...   51  195    11   \n",
       "1630  1631  115   6   95   6    23   3.4     0  18.8   3  ...   52  182     9   \n",
       "\n",
       "      Nzeros  Mode  Mean  Median  Variance  Tendency  Classe  \n",
       "0          0   117   115     117        19         0       0  \n",
       "1          0   117   117     119        21         0       0  \n",
       "2          0   119   120     120        14         0       0  \n",
       "3          1   119   119     120        13         0       0  \n",
       "4          0   119   118     119        13         0       0  \n",
       "...      ...   ...   ...     ...       ...       ...     ...  \n",
       "1626       1   133   124     130        35         0       0  \n",
       "1627       0   121   124     126        25         0       0  \n",
       "1628       1   129   125     127        25         0       0  \n",
       "1629       0   125   124     126        24         0       0  \n",
       "1630       0   119   116     118        21         0       0  \n",
       "\n",
       "[1631 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NB_FEATURES = 23 #Hardcodé\n",
    "\n",
    "data = pd.read_csv('./XXX.csv', sep=';') \n",
    "\n",
    "X = data.iloc[:, 1:NB_FEATURES].values # On ne prend pas en compte l'id\n",
    "y = data.iloc[:, NB_FEATURES].values.astype(float)\n",
    "\n",
    "# X exemples de Y features\n",
    "print(f\"Taille des données : {X.shape}\")\n",
    "\n",
    "# Répartition des classes du training set\n",
    "pd.DataFrame(y).plot.hist()\n",
    "\n",
    "# Division du dataset\n",
    "X_train, X_test, y_train, y_test = split_train_test(X, y)\n",
    "\n",
    "# Print dataset\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix du meilleur classifieur (au monde)\n",
    "\n",
    "*Pour faciliter le choix : [lien](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier LinearSVC : \n",
      "\tExecution time = 0.19416236877441406\n",
      "\tAccuracy : 0.925 +/- 0.022\n",
      "Classifier KNN : \n",
      "\tExecution time = 0.08836555480957031\n",
      "\tAccuracy : 0.914 +/- 0.019\n",
      "Classifier SVC : \n",
      "\tExecution time = 0.349409818649292\n",
      "\tAccuracy : 0.928 +/- 0.021\n",
      "Classifier GaussianNB : \n",
      "\tExecution time = 0.06255960464477539\n",
      "\tAccuracy : 0.886 +/- 0.026\n",
      "Classifier RF : \n",
      "\tExecution time = 1.7399826049804688\n",
      "\tAccuracy : 0.960 +/- 0.010\n",
      "Classifier SGDClassifier : \n",
      "\tExecution time = 0.04804348945617676\n",
      "\tAccuracy : 0.917 +/- 0.016\n",
      "Classifier LogisticRegression : \n",
      "\tExecution time = 0.10408854484558105\n",
      "\tAccuracy : 0.926 +/- 0.020\n",
      "Classifier AdaBoost : \n",
      "\tExecution time = 0.930213212966919\n",
      "\tAccuracy : 0.950 +/- 0.019\n",
      "Classifier MultilayerPerceptron : \n",
      "\tExecution time = 9.74360466003418\n",
      "\tAccuracy : 0.947 +/- 0.016\n",
      "Classifier Bagging : \n",
      "\tExecution time = 1.6813812255859375\n",
      "\tAccuracy : 0.924 +/- 0.023\n"
     ]
    }
   ],
   "source": [
    "# Donne un premier apperçu des performances\n",
    "kfcv_test_classifiers(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle(s) retenu(s)\n",
    "model = MLPClassifier()\n",
    "\n",
    "# Pipeline de classification\n",
    "pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),                # Etape 1 : normalisation\n",
    "        ('reduce_dims', PCA(n_components=15)),     # Etape 2 : réduction de dimension\n",
    "        ('clf', model)])                           # Etape 3 : classification\n",
    "\n",
    "opts = {\n",
    "    'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "    'clf__hidden_layer_sizes': [(20,10),(20,)],\n",
    "    'clf__activation': ['tanh', 'relu'],\n",
    "    'clf__solver': ['sgd', 'adam'],\n",
    "    'clf__alpha': [0.0001, 0.001, 0.05],\n",
    "    'clf__learning_rate': ['constant','adaptive'],\n",
    "    'clf__random_state': [1]\n",
    "}\n",
    "\n",
    "gs = gridsearch(X, y, pipe, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:0.972027972027972 | recall:0.879746835443038 | accuracy:0.9573283858998145\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# Testing\n",
    "y_pred = pipe.predict(X_test)\n",
    "precision_recall_accuracy(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application sur le jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des données : (495, 22)\n",
      "(array([315, 180], dtype=int64), array([0. , 0.5, 1. ]))\n",
      "Voila c'est dans la boite.\n"
     ]
    }
   ],
   "source": [
    "# On récupère les données de test\n",
    "data_eval = pd.read_csv('./XXX.csv', sep=';') \n",
    "X_eval = data_eval.iloc[:, 1:NB_FEATURES].values \n",
    "X_eval_id = data_eval[\"ID\"].values # ID des exemples\n",
    "\n",
    "# 1631 exemples de 22 features\n",
    "print(f\"Taille des données : {X_eval.shape}\")\n",
    "\n",
    "# Predict avec le modèle entrainé (pipeline en fait)\n",
    "y_pred = pipe.predict(X_eval)\n",
    "\n",
    "# Juste pour être sûr\n",
    "assert(X_eval_id.shape[0] == y_pred.shape[0])\n",
    "\n",
    "# Trick pour récupérer le nombre de 0 et de 1\n",
    "# Pas très propre cela dit...\n",
    "# Predicitons : 315 de la classe \"0\" et 180 de la classe \"1\"\n",
    "print(np.histogram(y_pred,bins=[0,0.5,1])) \n",
    "\n",
    "# Sauvegarde dans un CSV\n",
    "pd.DataFrame({\"id\":X_eval_id,\"pred\":y_pred}).to_csv(\"OUT.csv\", sep=\";\", header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
